{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations and main hyperparammeters\n",
    "EPOCHS = 150\n",
    "NNBATCHSIZE = 16\n",
    "GROUP_BATCH_SIZE = 4000\n",
    "look_back = 1024\n",
    "SEED = 321\n",
    "LR = 0.001\n",
    "SPLITS = 5\n",
    "\n",
    "outdir = 'wavenet_models'\n",
    "flip = False\n",
    "noise = False\n",
    "\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "def read_data():\n",
    "    train = pd.read_csv('/input/train.csv', dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int32})\n",
    "    test  = pd.read_csv('/input/test.csv', dtype={'time': np.float32, 'signal': np.float32})\n",
    "    sub  = pd.read_csv('/input/sample_submission.csv', dtype={'time': np.float32})\n",
    "    return train, test, sub\n",
    "\n",
    "# create batches of 4000 observations\n",
    "def batching(df, batch_size):\n",
    "    #print(df)\n",
    "    df['group'] = df.groupby(df.index//batch_size, sort=False)['signal'].agg(['ngroup']).values\n",
    "    df['group'] = df['group'].astype(np.uint16)\n",
    "    return df\n",
    "\n",
    "# normalize the data (standard scaler). We can also try other scalers for a better score!\n",
    "def normalize(train, test):\n",
    "    train_input_mean = train.signal.mean()\n",
    "    train_input_sigma = train.signal.std()\n",
    "    train['signal'] = (train.signal - train_input_mean) / train_input_sigma\n",
    "    test['signal'] = (test.signal - train_input_mean) / train_input_sigma\n",
    "    train['signal'] = (((train.signal - train.signal.min()) / (train.signal.max()-train.signal.min()))-0.5)*2\n",
    "    test['signal'] = (((test.signal - test.signal.min()) / (test.signal.max()-test.signal.min()))-0.5)*2\n",
    "    return train, test\n",
    "\n",
    "train, test, sample_submission = read_data()\n",
    "train, test = normalize(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = 10\n",
    "sample_size = 500000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 林先輩wavenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def encode_mu_law(x, mu=256):\n",
    "    \"\"\"PERFORM MU-LAW ENCODING.\n",
    "    Args:\n",
    "        x (ndarray): Audio signal with the range from -1 to 1.\n",
    "        mu (int): Quantized level.\n",
    "    Returns:\n",
    "        ndarray: Quantized audio signal with the range from 0 to mu - 1.\n",
    "    \"\"\"\n",
    "    mu = mu - 1\n",
    "    fx = np.sign(x) * np.log(1 + mu * np.abs(x)) / np.log(1 + mu)\n",
    "    return np.floor((fx + 1) / 2 * mu + 0.5).astype(np.int64)\n",
    "\n",
    "\n",
    "def decode_mu_law(y, mu=256):\n",
    "    \"\"\"PERFORM MU-LAW DECODING.\n",
    "    Args:\n",
    "        x (ndarray): Quantized audio signal with the range from 0 to mu - 1.\n",
    "        mu (int): Quantized level.\n",
    "    Returns:\n",
    "        ndarray: Audio signal with the range from -1 to 1.\n",
    "    \"\"\"\n",
    "    mu = mu - 1\n",
    "    fx = (y - 0.5) / mu * 2 - 1\n",
    "    x = np.sign(fx) / mu * ((1 + mu) ** np.abs(fx) - 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def initialize(m):\n",
    "    \"\"\"INITILIZE CONV WITH XAVIER.\n",
    "    Arg:\n",
    "        m (torch.nn.Module): Pytorch nn module instance.\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    if isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.constant_(m.weight, 1.0)\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "class OneHot(nn.Module):\n",
    "    \"\"\"CONVERT TO ONE-HOT VECTOR.\n",
    "    Args:\n",
    "        depth (int): Dimension of one-hot vector\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, depth):\n",
    "        super(OneHot, self).__init__()\n",
    "        self.depth = depth\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"FORWARD CALCULATION.\n",
    "        Arg:\n",
    "            x (LongTensor): Long tensor variable with the shape (B, T).\n",
    "        Returns:\n",
    "            Tensor: Float tensor variable with the shape (B, depth, T).\n",
    "        \"\"\"\n",
    "        x = x % self.depth\n",
    "        x = torch.unsqueeze(x, 2)\n",
    "        x_onehot = x.new_zeros(x.size(0), x.size(1), self.depth).float()\n",
    "\n",
    "        return x_onehot.scatter_(2, x, 1)\n",
    "\n",
    "\n",
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\"1D DILATED CAUSAL CONVOLUTION.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, bias=True):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "        self.padding = padding = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                              padding=padding, dilation=dilation, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"FORWARD CALCULATION.\n",
    "        Args:\n",
    "            x (Tensor): Float tensor variable with the shape  (B, C, T).\n",
    "        Returns:\n",
    "            Tensor: Float tensor variable with the shape (B, C, T).\n",
    "        \"\"\"\n",
    "        x = self.conv(x)\n",
    "        if self.padding != 0:\n",
    "            x = x[:, :, :-self.padding]\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSampling(nn.Module):\n",
    "    \"\"\"UPSAMPLING LAYER WITH DECONVOLUTION.\n",
    "    Args:\n",
    "        upsampling_factor (int): Upsampling factor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, upsampling_factor, bias=True):\n",
    "        super(UpSampling, self).__init__()\n",
    "        self.upsampling_factor = upsampling_factor\n",
    "        self.bias = bias\n",
    "        self.conv = nn.ConvTranspose2d(1, 1,\n",
    "                                       kernel_size=(1, self.upsampling_factor),\n",
    "                                       stride=(1, self.upsampling_factor),\n",
    "                                       bias=self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"FORWARD CALCULATION.\n",
    "        Args:\n",
    "            x (Tensor): Float tensor variable with the shape (B, C, T).\n",
    "        Returns:\n",
    "            Tensor: Float tensor variable with the shape (B, C, T'),\n",
    "                where T' = T * upsampling_factor.\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(1)  # B x 1 x C x T\n",
    "        x = self.conv(x)  # B x 1 x C x T'\n",
    "        return x.squeeze(1)\n",
    "\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    \"\"\"CONDITIONAL WAVENET.\n",
    "    Args:\n",
    "        n_quantize (int): Number of quantization.\n",
    "        n_aux (int): Number of aux feature dimension.\n",
    "        n_resch (int): Number of filter channels for residual block.\n",
    "        n_skipch (int): Number of filter channels for skip connection.\n",
    "        dilation_depth (int): Number of dilation depth (e.g. if set 10, max dilation = 2^(10-1)).\n",
    "        dilation_repeat (int): Number of dilation repeat.\n",
    "        kernel_size (int): Filter size of dilated causal convolution.\n",
    "        upsampling_factor (int): Upsampling factor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_quantize=256, n_aux=28, n_resch=512, n_skipch=256,\n",
    "                 dilation_depth=10, dilation_repeat=3, kernel_size=2, upsampling_factor=0,class_num=11):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.n_aux = n_aux\n",
    "        self.n_quantize = n_quantize\n",
    "        self.n_resch = n_resch\n",
    "        self.n_skipch = n_skipch\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation_depth = dilation_depth\n",
    "        self.dilation_repeat = dilation_repeat\n",
    "        self.upsampling_factor = upsampling_factor\n",
    "        self.class_num = class_num\n",
    "\n",
    "        self.dilations = [2 ** i for i in range(self.dilation_depth)] * self.dilation_repeat\n",
    "        self.receptive_field = (self.kernel_size - 1) * sum(self.dilations) + 1\n",
    "\n",
    "        # for preprocessing\n",
    "        self.onehot = OneHot(self.n_quantize)\n",
    "        self.causal = CausalConv1d(self.n_quantize, self.n_resch, self.kernel_size)\n",
    "        if self.upsampling_factor > 0:\n",
    "            self.upsampling = UpSampling(self.upsampling_factor)\n",
    "\n",
    "        # for residual blocks\n",
    "        self.dil_sigmoid = nn.ModuleList()\n",
    "        self.dil_tanh = nn.ModuleList()\n",
    "        self.aux_1x1_sigmoid = nn.ModuleList()\n",
    "        self.aux_1x1_tanh = nn.ModuleList()\n",
    "        self.skip_1x1 = nn.ModuleList()\n",
    "        self.res_1x1 = nn.ModuleList()\n",
    "        for d in self.dilations:\n",
    "            self.dil_sigmoid += [CausalConv1d(self.n_resch, self.n_resch, self.kernel_size, d)]\n",
    "            self.dil_tanh += [CausalConv1d(self.n_resch, self.n_resch, self.kernel_size, d)]\n",
    "            self.aux_1x1_sigmoid += [nn.Conv1d(self.n_aux, self.n_resch, 1)]\n",
    "            self.aux_1x1_tanh += [nn.Conv1d(self.n_aux, self.n_resch, 1)]\n",
    "            self.skip_1x1 += [nn.Conv1d(self.n_resch, self.n_skipch, 1)]\n",
    "            self.res_1x1 += [nn.Conv1d(self.n_resch, self.n_resch, 1)]\n",
    "\n",
    "        # for postprocessing\n",
    "        self.conv_post_1 = nn.Conv1d(self.n_skipch, self.n_skipch, 1)\n",
    "        self.conv_post_2 = nn.Conv1d(self.n_skipch, self.n_quantize, 1)\n",
    "        self.out = nn.Linear(self.n_quantize, self.class_num)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        \"\"\"FORWARD CALCULATION.\n",
    "        Args:\n",
    "            x (Tensor): Long tensor variable with the shape (B, T).\n",
    "            h (Tensor): Float tensor variable with the shape (B, n_aux, T),\n",
    "        Returns:\n",
    "            Tensor: Float tensor variable with the shape (B, T, n_quantize).\n",
    "        \"\"\"\n",
    "        # preprocess\n",
    "        output = self._preprocess(x)\n",
    "        if self.upsampling_factor > 0:\n",
    "            h = self.upsampling(h)\n",
    "\n",
    "        # residual block\n",
    "        skip_connections = []\n",
    "        for l in range(len(self.dilations)):\n",
    "            output, skip = self._residual_forward(\n",
    "                output, h, self.dil_sigmoid[l], self.dil_tanh[l],\n",
    "                self.aux_1x1_sigmoid[l], self.aux_1x1_tanh[l],\n",
    "                self.skip_1x1[l], self.res_1x1[l])\n",
    "            skip_connections.append(skip)\n",
    "\n",
    "        # skip-connection part\n",
    "        output = sum(skip_connections)\n",
    "        output = self._postprocess(output)# B x T x C\n",
    "        #self.layer4 = self._make_layers(64, 128, 3, 1)\n",
    "        #self.fc = nn.Linear(128, 11)\n",
    "        #x = x.permute(0, 2, 1)\n",
    "        #x = self.fc(x)\n",
    "        output = F.softmax(self.out(output))#B x T x class_num, class_num = 11\n",
    "\n",
    "        return output\n",
    "\n",
    "    def generate(self, x, h, n_samples, intervals=None, mode=\"sampling\"):\n",
    "        \"\"\"GENERATE WAVEFORM WITH NAIVE CALCULATION.\n",
    "        Args:\n",
    "            x (Tensor): Long tensor variable with the shape (1, T).\n",
    "            h (Tensor): Float tensor variable with the shape (1, n_aux, n_samples + T).\n",
    "            n_samples (int): Number of samples to be generated.\n",
    "            intervals (int): Log interval.\n",
    "            mode (str): \"sampling\" or \"argmax\".\n",
    "        Returns:\n",
    "            ndarray: Generated quantized wavenform (n_samples,).\n",
    "        \"\"\"\n",
    "        # upsampling\n",
    "        if self.upsampling_factor > 0:\n",
    "            h = self.upsampling(h)\n",
    "\n",
    "        # padding if the length less than receptive field size\n",
    "        n_pad = self.receptive_field - x.size(1)\n",
    "        if n_pad > 0:\n",
    "            x = F.pad(x, (n_pad, 0), \"constant\", self.n_quantize // 2)\n",
    "            h = F.pad(h, (n_pad, 0), \"replicate\")\n",
    "\n",
    "        # generate\n",
    "        samples = x[0].tolist()\n",
    "        start = time.time()\n",
    "        for i in range(n_samples):\n",
    "            current_idx = len(samples)\n",
    "            x = torch.tensor(samples[-self.receptive_field:]).long().view(1, -1)\n",
    "            h_ = h[:, :, current_idx - self.receptive_field: current_idx]\n",
    "\n",
    "            # calculate output\n",
    "            output = self._preprocess(x)\n",
    "            skip_connections = []\n",
    "            for l in range(len(self.dilations)):\n",
    "                output, skip = self._residual_forward(\n",
    "                    output, h_, self.dil_sigmoid[l], self.dil_tanh[l],\n",
    "                    self.aux_1x1_sigmoid[l], self.aux_1x1_tanh[l],\n",
    "                    self.skip_1x1[l], self.res_1x1[l])\n",
    "                skip_connections.append(skip)\n",
    "            output = sum(skip_connections)\n",
    "            output = self._postprocess(output)[0]  # T x n_quantize\n",
    "\n",
    "            # get waveform\n",
    "            if mode == \"sampling\":\n",
    "                posterior = F.softmax(output[-1], dim=0)\n",
    "                dist = torch.distributions.Categorical(posterior)\n",
    "                sample = dist.sample()\n",
    "            elif mode == \"argmax\":\n",
    "                sample = output[-1].argmax()\n",
    "            else:\n",
    "                logging.error(\"mode should be sampling or argmax\")\n",
    "                sys.exit(1)\n",
    "            samples.append(sample)\n",
    "\n",
    "            # show progress\n",
    "            if intervals is not None and (i + 1) % intervals == 0:\n",
    "                logging.info(\"%d/%d estimated time = %.3f sec (%.3f sec / sample)\" % (\n",
    "                    i + 1, n_samples,\n",
    "                    (n_samples - i - 1) * ((time.time() - start) / intervals),\n",
    "                    (time.time() - start) / intervals))\n",
    "                start = time.time()\n",
    "\n",
    "        return np.array(samples[-n_samples:])\n",
    "\n",
    "    def fast_generate(self, x, h, n_samples, intervals=None, mode=\"sampling\"):\n",
    "        \"\"\"GENERATE WAVEFORM WITH FAST ALGORITHM.\n",
    "        Args:\n",
    "            x (tensor): Long tensor variable with the shape  (1, T).\n",
    "            h (tensor): Float tensor variable with the shape  (1, n_aux, n_samples + T).\n",
    "            n_samples (int): Number of samples to be generated.\n",
    "            intervals (int): Log interval.\n",
    "            mode (str): \"sampling\" or \"argmax\".\n",
    "        Returns:\n",
    "            ndarray: Generated quantized wavenform (n_samples,).\n",
    "        References:\n",
    "            Fast Wavenet Generation Algorithm: https://arxiv.org/abs/1611.09482\n",
    "        \"\"\"\n",
    "        # upsampling\n",
    "        if self.upsampling_factor > 0:\n",
    "            h = self.upsampling(h)\n",
    "\n",
    "        # padding if the length less than\n",
    "        n_pad = self.receptive_field - x.size(1)\n",
    "        if n_pad > 0:\n",
    "            x = F.pad(x, (n_pad, 0), \"constant\", self.n_quantize // 2)\n",
    "            h = F.pad(h, (n_pad, 0), \"replicate\")\n",
    "\n",
    "        # prepare buffer\n",
    "        output = self._preprocess(x)\n",
    "        h_ = h[:, :, :x.size(1)]\n",
    "        output_buffer = []\n",
    "        buffer_size = []\n",
    "        for l, d in enumerate(self.dilations):\n",
    "            output, _ = self._residual_forward(\n",
    "                output, h_, self.dil_sigmoid[l], self.dil_tanh[l],\n",
    "                self.aux_1x1_sigmoid[l], self.aux_1x1_tanh[l],\n",
    "                self.skip_1x1[l], self.res_1x1[l])\n",
    "            if d == 2 ** (self.dilation_depth - 1):\n",
    "                buffer_size.append(self.kernel_size - 1)\n",
    "            else:\n",
    "                buffer_size.append(d * 2 * (self.kernel_size - 1))\n",
    "            output_buffer.append(output[:, :, -buffer_size[l] - 1: -1])\n",
    "\n",
    "        # generate\n",
    "        samples = x[0]\n",
    "        start = time.time()\n",
    "        for i in range(n_samples):\n",
    "            output = samples[-self.kernel_size * 2 + 1:].unsqueeze(0)\n",
    "            output = self._preprocess(output)\n",
    "            h_ = h[:, :, samples.size(0) - 1].contiguous().view(1, self.n_aux, 1)\n",
    "            output_buffer_next = []\n",
    "            skip_connections = []\n",
    "            for l, d in enumerate(self.dilations):\n",
    "                output, skip = self._generate_residual_forward(\n",
    "                    output, h_, self.dil_sigmoid[l], self.dil_tanh[l],\n",
    "                    self.aux_1x1_sigmoid[l], self.aux_1x1_tanh[l],\n",
    "                    self.skip_1x1[l], self.res_1x1[l])\n",
    "                output = torch.cat([output_buffer[l], output], dim=2)\n",
    "                output_buffer_next.append(output[:, :, -buffer_size[l]:])\n",
    "                skip_connections.append(skip)\n",
    "\n",
    "            # update buffer\n",
    "            output_buffer = output_buffer_next\n",
    "\n",
    "            # get predicted sample\n",
    "            output = sum(skip_connections)\n",
    "            output = self._postprocess(output)[0]\n",
    "            if mode == \"sampling\":\n",
    "                posterior = F.softmax(output[-1], dim=0)\n",
    "                dist = torch.distributions.Categorical(posterior)\n",
    "                sample = dist.sample().unsqueeze(0)\n",
    "            elif mode == \"argmax\":\n",
    "                sample = output.argmax(-1)\n",
    "            else:\n",
    "                logging.error(\"mode should be sampling or argmax\")\n",
    "                sys.exit(1)\n",
    "            samples = torch.cat([samples, sample], dim=0)\n",
    "\n",
    "            # show progress\n",
    "            if intervals is not None and (i + 1) % intervals == 0:\n",
    "                logging.info(\"%d/%d estimated time = %.3f sec (%.3f sec / sample)\" % (\n",
    "                    i + 1, n_samples,\n",
    "                    (n_samples - i - 1) * ((time.time() - start) / intervals),\n",
    "                    (time.time() - start) / intervals))\n",
    "                start = time.time()\n",
    "\n",
    "        return samples[-n_samples:].cpu().numpy()\n",
    "\n",
    "    def batch_fast_generate(self, x, h, n_samples_list, intervals=None, mode=\"sampling\"):\n",
    "        \"\"\"GENERATE WAVEFORM WITH FAST ALGORITHM IN BATCH MODE.\n",
    "        Args:\n",
    "            x (tensor): Long tensor variable with the shape (B, T).\n",
    "            h (tensor): Float tensor variable with the shape (B, n_aux, max(n_samples_list) + T).\n",
    "            n_samples_list (list): List of number of samples to be generated (B,).\n",
    "            intervals (int): Log interval.\n",
    "            mode (str): \"sampling\" or \"argmax\".\n",
    "        Returns:\n",
    "            list: List of ndarray which is generated quantized wavenform.\n",
    "        \"\"\"\n",
    "        # get min max length\n",
    "        max_n_samples = max(n_samples_list)\n",
    "        min_n_samples = min(n_samples_list)\n",
    "        min_idx = np.argmin(n_samples_list)\n",
    "\n",
    "        # upsampling\n",
    "        if self.upsampling_factor > 0:\n",
    "            h = self.upsampling(h)\n",
    "\n",
    "        # padding if the length less than\n",
    "        n_pad = self.receptive_field - x.size(1)\n",
    "        if n_pad > 0:\n",
    "            x = F.pad(x, (n_pad, 0), \"constant\", self.n_quantize // 2)\n",
    "            h = F.pad(h, (n_pad, 0), \"replicate\")\n",
    "\n",
    "        # prepare buffer\n",
    "        output = self._preprocess(x)\n",
    "        h_ = h[:, :, :x.size(1)]\n",
    "        output_buffer = []\n",
    "        buffer_size = []\n",
    "        for l, d in enumerate(self.dilations):\n",
    "            output, _ = self._residual_forward(\n",
    "                output, h_, self.dil_sigmoid[l], self.dil_tanh[l],\n",
    "                self.aux_1x1_sigmoid[l], self.aux_1x1_tanh[l],\n",
    "                self.skip_1x1[l], self.res_1x1[l])\n",
    "            if d == 2 ** (self.dilation_depth - 1):\n",
    "                buffer_size.append(self.kernel_size - 1)\n",
    "            else:\n",
    "                buffer_size.append(d * 2 * (self.kernel_size - 1))\n",
    "            output_buffer.append(output[:, :, -buffer_size[l] - 1: -1])\n",
    "\n",
    "        # generate\n",
    "        samples = x  # B x T\n",
    "        end_samples = []\n",
    "        start = time.time()\n",
    "        for i in range(max_n_samples):\n",
    "            output = samples[:, -self.kernel_size * 2 + 1:]\n",
    "            output = self._preprocess(output)  # B x C x T\n",
    "            h_ = h[:, :, samples.size(-1) - 1].contiguous().unsqueeze(-1)  # B x C x 1\n",
    "            output_buffer_next = []\n",
    "            skip_connections = []\n",
    "            for l, d in enumerate(self.dilations):\n",
    "                output, skip = self._generate_residual_forward(\n",
    "                    output, h_, self.dil_sigmoid[l], self.dil_tanh[l],\n",
    "                    self.aux_1x1_sigmoid[l], self.aux_1x1_tanh[l],\n",
    "                    self.skip_1x1[l], self.res_1x1[l])\n",
    "                output = torch.cat([output_buffer[l], output], dim=2)\n",
    "                output_buffer_next.append(output[:, :, -buffer_size[l]:])\n",
    "                skip_connections.append(skip)\n",
    "\n",
    "            # update buffer\n",
    "            output_buffer = output_buffer_next\n",
    "\n",
    "            # get predicted sample\n",
    "            output = sum(skip_connections)\n",
    "            output = self._postprocess(output)[:, -1]  # B x n_quantize\n",
    "            if mode == \"sampling\":\n",
    "                posterior = F.softmax(output, dim=-1)\n",
    "                dist = torch.distributions.Categorical(posterior)\n",
    "                sample = dist.sample()  # B\n",
    "            elif mode == \"argmax\":\n",
    "                sample = output.argmax(-1)  # B\n",
    "            else:\n",
    "                logging.error(\"mode should be sampling or argmax\")\n",
    "                sys.exit(1)\n",
    "            samples = torch.cat([samples, sample.view(-1, 1)], dim=1)\n",
    "\n",
    "            # show progress\n",
    "            if intervals is not None and (i + 1) % intervals == 0:\n",
    "                logging.info(\"%d/%d estimated time = %.3f sec (%.3f sec / sample)\" % (\n",
    "                    i + 1, max_n_samples,\n",
    "                    (max_n_samples - i - 1) * ((time.time() - start) / intervals),\n",
    "                    (time.time() - start) / intervals))\n",
    "                start = time.time()\n",
    "\n",
    "            # check length\n",
    "            if (i + 1) == min_n_samples:\n",
    "                while True:\n",
    "                    # get finished sample\n",
    "                    end_samples += [samples[min_idx, -min_n_samples:].cpu().numpy()]\n",
    "                    # get index of unfinished samples\n",
    "                    idx_list = [idx for idx in range(len(n_samples_list)) if idx != min_idx]\n",
    "                    if len(idx_list) == 0:\n",
    "                        # break when all of samples are finished\n",
    "                        break\n",
    "                    else:\n",
    "                        # remove finished sample\n",
    "                        samples = samples[idx_list]\n",
    "                        h = h[idx_list]\n",
    "                        output_buffer = [out_[idx_list] for out_ in output_buffer]\n",
    "                        del n_samples_list[min_idx]\n",
    "                        # update min length\n",
    "                        prev_min_n_samples = min_n_samples\n",
    "                        min_n_samples = min(n_samples_list)\n",
    "                        min_idx = np.argmin(n_samples_list)\n",
    "\n",
    "                    # break when there is no same length samples\n",
    "                    if min_n_samples != prev_min_n_samples:\n",
    "                        break\n",
    "\n",
    "        return end_samples\n",
    "\n",
    "    def _preprocess(self, x):\n",
    "        x = self.onehot(x).transpose(1, 2)\n",
    "        output = self.causal(x)\n",
    "        return output\n",
    "\n",
    "    def _postprocess(self, x):\n",
    "        output = F.relu(x)\n",
    "        output = self.conv_post_1(output)\n",
    "        output = F.relu(output)  # B x C x T\n",
    "        output = self.conv_post_2(output).transpose(1, 2)  # B x T x C\n",
    "        return output\n",
    "\n",
    "    def _residual_forward(self, x, h, dil_sigmoid, dil_tanh,\n",
    "                          aux_1x1_sigmoid, aux_1x1_tanh, skip_1x1, res_1x1):\n",
    "        output_sigmoid = dil_sigmoid(x)\n",
    "        output_tanh = dil_tanh(x)\n",
    "        aux_output_sigmoid = aux_1x1_sigmoid(h)\n",
    "        aux_output_tanh = aux_1x1_tanh(h)\n",
    "        output = torch.sigmoid(output_sigmoid + aux_output_sigmoid) * \\\n",
    "            torch.tanh(output_tanh + aux_output_tanh)\n",
    "        skip = skip_1x1(output)\n",
    "        output = res_1x1(output)\n",
    "        output = output + x\n",
    "        return output, skip\n",
    "\n",
    "    def _generate_residual_forward(self, x, h, dil_sigmoid, dil_tanh,\n",
    "                                   aux_1x1_sigmoid, aux_1x1_tanh, skip_1x1, res_1x1):\n",
    "        output_sigmoid = dil_sigmoid(x)[:, :, -1:]\n",
    "        output_tanh = dil_tanh(x)[:, :, -1:]\n",
    "        aux_output_sigmoid = aux_1x1_sigmoid(h)\n",
    "        aux_output_tanh = aux_1x1_tanh(h)\n",
    "        output = torch.sigmoid(output_sigmoid + aux_output_sigmoid) * \\\n",
    "            torch.tanh(output_tanh + aux_output_tanh)\n",
    "        skip = skip_1x1(output)\n",
    "        output = res_1x1(output)\n",
    "        output = output + x[:, :, -1:]  # B x C x 1\n",
    "        return output, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class subIronDataset(Dataset):\n",
    "    def __init__(self, data, labels_df=None, training=True, index=None, mu=256, look_back=1024):\n",
    "        self.data = data\n",
    "        if training:\n",
    "            #self.labels = pd.get_dummies(labels_df)\n",
    "            self.labels = labels_df\n",
    "        if index is not None:\n",
    "            self.data = data.iloc[index]\n",
    "            \n",
    "        self.training = training\n",
    "        self.index = index\n",
    "        self.mu = mu\n",
    "        self.len_sample = 500000 #１回の実験でサンプリングしたデータの点\n",
    "        self.look_back = look_back\n",
    "        self.class_num = 11\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.index is not None:\n",
    "            return len(self.index)\n",
    "        else:\n",
    "            return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.index is not None:\n",
    "            idx = self.index[idx]\n",
    "        data = np.array([encode_mu_law(self.data[idx], mu=self.mu)])\n",
    "        #labelを返す際にlook_back分のクラスを付与 label=(batch, look_back, class_num)\n",
    "        #ただし、実装の簡単のためidxにはintが来る(dataloader)での想定とするlabel=(look_back, class_num)\n",
    "        #look_backの部分は[now-look_back+1:now+1]という順番で入っている\n",
    "        if self.training:\n",
    "            if idx%self.len_sample <= self.look_back-1: #look_back未満の部分でmodeで保管する(もし精度が悪ければ変える)\n",
    "                labels = np.zeros(self.look_back)\n",
    "                new_idx = idx%self.len_sample\n",
    "                num_batch = idx//self.len_sample\n",
    "                labels[self.look_back-new_idx-1:] = self.labels.iloc[self.len_sample*num_batch:idx+1].values\n",
    "                labels[:self.look_back-new_idx-1] = labels[self.look_back-new_idx-1:].sum(axis=0).argmax()\n",
    "                #one_hot = np.zeros(self.class_num)\n",
    "                #print(labels[self.look_back-idx-1:].sum(axis=0).argmax())\n",
    "                #one_hot[labels[self.look_back-idx-1:].sum(axis=0).argmax()] = 1 #mode\n",
    "                #print(one_hot)\n",
    "                #labels[:self.look_back-idx-1] = one_hot \n",
    "            else: #look_back以降なので気にせず詰め込めばよい\n",
    "                labels = self.labels.iloc[idx-self.look_back+1:idx+1].values\n",
    "                #print(self.labels.iloc[idx-self.look_back+1:idx+1].values)\n",
    "            #labels = self.labels.iloc[idx].values\n",
    "            return [data, labels.astype(\"int64\")]\n",
    "        else:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNBATCHSIZE = 200\n",
    "look_back=128\n",
    "# train_dataset = IronDataset(train_df, train[\"open_channels\"], training=True,look_back=look_back)\n",
    "train_dataset = subIronDataset(train[\"signal\"].values, train[\"open_channels\"], training=True,look_back=look_back)\n",
    "# test_dataset = IronDataset(test_df, training=False, look_back=look_back)\n",
    "test_dataset = subIronDataset(test[\"signal\"].values, training=False,look_back=look_back)\n",
    "# idx = [0,4999999,499999,500000,500001,4999996]\n",
    "# X, y = train_dataset[idx]\n",
    "# train_dataloader = DataLoader(train_dataset, NNBATCHSIZE, shuffle=True, num_workers=8, pin_memory=True)\n",
    "# test_dataloader = DataLoader(test_dataset, NNBATCHSIZE, shuffle=False, num_workers=8, pin_memory=True)\n",
    "#-0.5805814\n",
    "train_dataloader = DataLoader(train_dataset, NNBATCHSIZE, shuffle=True, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.receptive_field: 1023\n",
      "(1,) (128,)\n",
      "torch.Size([200, 1]) torch.Size([200, 128])\n",
      "torch.Size([200, 128, 11])\n"
     ]
    }
   ],
   "source": [
    "#h = (B, n_aux, T)\n",
    "# n_aux = 1\n",
    "# model = WaveNet(n_quantize=256, n_aux=n_aux, n_resch=128, n_skipch=128,\n",
    "#                  dilation_depth=9, dilation_repeat=2, kernel_size=2, upsampling_factor=0)\n",
    "# print(\"model.receptive_field:\",model.receptive_field)\n",
    "# h = torch.zeros((200, n_aux, look_back))\n",
    "# x,y = train_dataset[0]\n",
    "# print(x.shape, y.shape)\n",
    "# # print(x, y)\n",
    "# for x, y in train_dataloader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     pred = model(x, h)\n",
    "#     print(pred.data.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25600, 11])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600, 11]) torch.Size([25600])\n",
      "tensor([[0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
      "        [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
      "        [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
      "        ...,\n",
      "        [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
      "        [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
      "        [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([7, 8, 7,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# print(pred.contiguous().view(-1,11).shape)\n",
    "# print(y.contiguous().view(-1).shape)\n",
    "# a = pred.contiguous().view(-1,11)\n",
    "# # b = torch.LongTensor(y.contiguous().view(-1))\n",
    "# b = y.contiguous().view(-1)\n",
    "# print(a.shape, b.shape)\n",
    "# print(a)\n",
    "# print(b)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# loss = criterion(a,b)\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, checkpoint_path='checkpoint.pt', is_maximize=True):\n",
    "        self.patience, self.delta, self.checkpoint_path = patience, delta, checkpoint_path\n",
    "        self.counter, self.best_score = 0, None\n",
    "        self.is_maximize = is_maximize\n",
    "\n",
    "\n",
    "    def load_best_weights(self, model):\n",
    "        model.load_state_dict(torch.load(self.checkpoint_path))\n",
    "\n",
    "    def __call__(self, score, model):\n",
    "        if self.best_score is None or \\\n",
    "                (score > self.best_score + self.delta if self.is_maximize else score < self.best_score - self.delta):\n",
    "            torch.save(model.state_dict(), self.checkpoint_path)\n",
    "            self.best_score, self.counter = score, 0\n",
    "            return 1\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return 2\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の方法\n",
    "\n",
    "* マイ時刻のクロスエントロピーを計算する方法（本家）  \n",
    "* 最終出力のみでクロスエントロピーを計算する（簡単）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "devise = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(devise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6ac9c075694d2fae9e43f37c015982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "Folder : 0 Epoch : 0\n",
      "Curr learning_rate: 0.010000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2591818bbf142ff84ecef525c94d85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non pred torch.Size([2000, 256, 11])\n",
      "non y    torch.Size([2000, 256])\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "n_aux = 1\n",
    "n_quantize = 256\n",
    "look_back = 256\n",
    "EPOCHS = 20\n",
    "NNBATCHSIZE = 4000\n",
    "lr = 1e-3\n",
    "h = torch.zeros((NNBATCHSIZE, n_aux, look_back)).to(devise)\n",
    "                \n",
    "oof_score = []\n",
    "for index,(train_index, val_index) in enumerate(kf.split(np.zeros((train.shape[0],1)), train[\"open_channels\"])):\n",
    "    train_dataset = subIronDataset(train[\"signal\"], train[\"open_channels\"], training=True, index=train_index, look_back=look_back)\n",
    "    train_dataloader = DataLoader(train_dataset, NNBATCHSIZE, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "    valid_dataset = subIronDataset(train[\"signal\"], train[\"open_channels\"], training=True, index=val_index, look_back=look_back)\n",
    "    valid_dataloader = DataLoader(valid_dataset, NNBATCHSIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    it = 0\n",
    "    \n",
    "    model = WaveNet(n_quantize=256, n_aux=n_aux, n_resch=64, n_skipch=128,\n",
    "                 dilation_depth=6, dilation_repeat=2, kernel_size=2, upsampling_factor=0)\n",
    "    model = model.to(devise)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10, is_maximize=True,\n",
    "                                   checkpoint_path=os.path.join(\"models\", \"checkpoint_fold_{}_iter_{}.pt\".format(index,it)))\n",
    "    cols = [\"loss\", \"F1\", \"val_loss\", \"val_F1\", \"lr\"]\n",
    "    results = pd.DataFrame(columns=cols)\n",
    "    weight = None#cal_weights()\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.2)\n",
    "    avg_train_losses, avg_valid_losses = [], []\n",
    "    \n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        print('**********************************')\n",
    "        print(\"Folder : {} Epoch : {}\".format(index, epoch))\n",
    "        print(\"Curr learning_rate: {:0.9f}\".format(optimizer.param_groups[0]['lr']))\n",
    "        train_losses, valid_losses = [], []\n",
    "        tr_loss_cls_item, val_loss_cls_item = [], []\n",
    "\n",
    "        model.train()  # prep model for training\n",
    "        train_preds, train_true = torch.Tensor([]).to(devise), torch.LongTensor([]).to(devise)\n",
    "        cnt = 0\n",
    "        for x, y in tqdm(train_dataloader):\n",
    "            x = x.to(devise)\n",
    "            y = y.to(devise)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #loss_fn(model(input), target).backward()\n",
    "            #optimizer.zero_grad()\n",
    "            predictions = model(x, h)\n",
    "            if cnt == 0:\n",
    "                print(\"non pred\",predictions.shape)\n",
    "                print(\"non y   \",y.shape)\n",
    "            loss = criterion( predictions.contiguous().view(-1, 11), y.contiguous().view(-1))\n",
    "\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            \n",
    "            #schedular.step()\n",
    "            # record training lossa\n",
    "            train_losses.append(loss.item())\n",
    "            train_true = torch.cat([train_true, y.contiguous()[:,-1]], 0)\n",
    "            train_preds = torch.cat([train_preds, predictions.contiguous()[:,-1,:]], 0)\n",
    "            cnt += 1\n",
    "        model.eval()  # prep model for evaluation\n",
    "        #optimizer.swap_swa_sgd()\n",
    "        val_preds, val_true = torch.Tensor([]).to(devise), torch.LongTensor([]).to(devise)\n",
    "        print('EVALUATION')\n",
    "        with torch.no_grad():\n",
    "            for x, y in valid_dataloader:\n",
    "                x = x.to(devise)\n",
    "                y = y.to(devise)\n",
    "\n",
    "                predictions = model(x, h)\n",
    "                loss = criterion(predictions.contiguous().view(-1, 11), y.contiguous().view(-1))\n",
    "                valid_losses.append(loss.item())\n",
    "\n",
    "                val_true = torch.cat([val_true, y.contiguous()[:,-1]], 0)\n",
    "                val_preds = torch.cat([val_preds, predictions.contiguous()[:,-1,:]], 0)\n",
    "\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        print(\"train_loss: {:0.6f}, valid_loss: {:0.6f}\".format(train_loss, valid_loss))\n",
    "\n",
    "        train_score = f1_score(train_true.cpu().detach().numpy(), train_preds.cpu().detach().numpy().argmax(1),\n",
    "                               labels=list(range(11)), average='macro')\n",
    "\n",
    "        val_score = f1_score(val_true.cpu().detach().numpy(), val_preds.cpu().detach().numpy().argmax(1),\n",
    "                             labels=list(range(11)), average='macro')\n",
    "        tmp = pd.DataFrame([train_loss, train_score, valid_loss, val_score, optimizer.param_groups[0]['lr']],columns=cols)\n",
    "        results = pd.concat([results, tmp], axis=0)\n",
    "        results.to_csv('output/results_fold{}.csv'.format(index), index=False)\n",
    "        schedular.step(val_score)\n",
    "        print(\"train_f1: {:0.6f}, valid_f1: {:0.6f}\".format(train_score, val_score))\n",
    "        res = early_stopping(val_score, model)\n",
    "        #print('fres:', res)\n",
    "        if  res == 2:\n",
    "            print(\"Early Stopping\")\n",
    "            print('folder %d global best val max f1 model score %f' % (index, early_stopping.best_score))\n",
    "            break\n",
    "        elif res == 1:\n",
    "            print('save folder %d global val max f1 model score %f' % (index, val_score))\n",
    "    print('Folder {} finally best global max f1 score is {}'.format(index, early_stopping.best_score))\n",
    "    oof_score.append(round(early_stopping.best_score, 6))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = subIronDataset(test[\"signal\"], training=False)\n",
    "test_dataloader = DataLoader(test_dataset, NNBATCHSIZE, shuffle=False)\n",
    "model.eval()\n",
    "pred_list = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_dataloader:\n",
    "        x = x.to(devise)\n",
    "        y = y.to(devise)\n",
    "\n",
    "        predictions = model(x, h)\n",
    "        pred_list.append(F.softmax(predictions.contiguous()[:,-1,:], dim=1).cpu().numpy()) # shape (512000, 11)\n",
    "    test_preds = np.vstack(pred_list) # shape [2000000, 11]\n",
    "    test_preds_all += test_preds\n",
    "print('all folder score is:%s'%str(oof_score))\n",
    "print('OOF mean score is: %f'% (sum(oof_score)/len(oof_score)))\n",
    "print('Generate submission.............')\n",
    "test_preds_all = test_preds_all / np.sum(test_preds_all, axis=1)[:, None]\n",
    "test_pred_frame = pd.DataFrame({'time': sample_submission['time'].astype(str),\n",
    "                                'open_channels': np.argmax(test_preds_all, axis=1)})\n",
    "test_pred_frame.to_csv(\"preds/wavenet_preds.csv\", index=False)\n",
    "print('over')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
